{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Local_Authority_Highway_codes\n",
    "lahc = ['E09000013','E09000014','E09000015']\n",
    "\n",
    "\n",
    "#Load the Dataset\n",
    "df = pd.read_csv('AccidentLondonBoroughs.csv')\n",
    "\n",
    "#Formating tyes\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform Date and Time values into ints\n",
    "\n",
    "dateMaxMin = [df['Date'].max(), df['Date'].min()]\n",
    "timeMaxMin = [df['Time'].max(), df['Time'].min()]\n",
    "\n",
    "dateDelta = dateMaxMin[0] - dateMaxMin[1]\n",
    "numOfDays = dateDelta.days\n",
    "\n",
    "timeDelta = timeMaxMin[0] - timeMaxMin[1]\n",
    "numOfMins = timeDelta.total_seconds() / 60\n",
    "\n",
    "\n",
    "print('dateStart: ' + str(dateMaxMin[1].date()) + '\\n' + 'totalDays: ' + str(numOfDays) + '\\n' + 'timeStart: ' + str(timeMaxMin[1].time()) + '\\n' + 'totalMins: ' +  str(numOfMins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateVals = []\n",
    "for i in df['Date']:\n",
    "    delt = i - dateMaxMin[1]\n",
    "    val = delt.days\n",
    "    dateVals.append(val)\n",
    "    \n",
    "timeVals = []\n",
    "for i in df['Time']:\n",
    "    delt = i - timeMaxMin[1]\n",
    "    val = int(delt.total_seconds() / 60)\n",
    "    timeVals.append(val)\n",
    "    \n",
    "df['DateVals'] = dateVals\n",
    "df['TimeVals'] = timeVals\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get columns associated with the LAHC\n",
    "data = pd.DataFrame(columns = df.columns.to_list())\n",
    "dfDict = dict(df.dtypes)\n",
    "\n",
    "for key, val in dfDict.items():\n",
    "    if val == 'int64' or val == 'float64':\n",
    "        data[key] = pd.to_numeric(data[key])\n",
    "    if key == 'Date':\n",
    "        data['Date'] = pd.to_datetime(data['Date'], format='%d/%m/%Y')\n",
    "    if key == 'Time':\n",
    "        data['Time'] = pd.to_datetime(data['Time'], format='%H:%M')\n",
    "    \n",
    "for lac in lahc :\n",
    "    lacRows = df.loc[df['Local_Authority_(Highway)'] == lac]\n",
    "    data = pd.concat([data, lacRows])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw, unclean, with outliers data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnAttri:\n",
    "    def __init__(self, name, ctype):\n",
    "        self.name = name\n",
    "        self.ctype = str(ctype)\n",
    "        self.range = []\n",
    "        self.values = []\n",
    "        self.empty = 0\n",
    "        self.notEmpty = 0\n",
    "        \n",
    "    def processCol(self, data):\n",
    "        for row in data[self.name]:\n",
    "            if row == -1 or str(row) == '-1':\n",
    "                self.empty += 1\n",
    "                continue\n",
    "            self.notEmpty += 1\n",
    "            \n",
    "            if self.ctype == 'int64' or self.ctype == 'float64':\n",
    "                if len(self.range) >= 1:\n",
    "                    if self.range[0] > row:\n",
    "                        self.range[0] = row\n",
    "                    if self.range[1] < row:\n",
    "                        self.range[1] = row\n",
    "                else:\n",
    "                    self.range.append(row)\n",
    "                    self.range.append(row)\n",
    "                    \n",
    "            if self.name == 'Date' or self.name == 'Time':\n",
    "                if len(self.range) >= 1:\n",
    "                    if self.range[0] > row:\n",
    "                        self.range[0] = row\n",
    "                    if self.range[1] < row:\n",
    "                        self.range[1] = row\n",
    "                else:\n",
    "                    self.range.append(row)\n",
    "                    self.range.append(row)\n",
    "                    \n",
    "            if not row in self.values:\n",
    "                self.values.append(row)\n",
    "                \n",
    "    def presentColAttri(self):\n",
    "        numerics = ['float64', 'int64' , 'datetime64[ns]']\n",
    "        \n",
    "        if not self.ctype in numerics:\n",
    "            self.range = ['Nan', 'Nan']\n",
    "        attri = {'Name': self.name, 'Type': self.ctype, 'Empty': self.empty, 'Full': self.notEmpty, 'Ratio': (self.empty / 10681) * 100, 'Min': self.range[0], 'Max': self.range[1], 'Unique': len(self.values)}\n",
    "        return attri\n",
    "    \n",
    "    def getValues(self):\n",
    "        return self.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColAttributes = []\n",
    "dataDict = dict(data.dtypes)\n",
    "\n",
    "for key, val in dataDict.items():\n",
    "    currCol = ColumnAttri(key, val)\n",
    "    currCol.processCol(data)\n",
    "    ColAttributes.append(currCol)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colDF = pd.DataFrame(columns=['Name','Type', 'Empty', 'Full', 'Ratio', 'Min', 'Max', 'Unique'])\n",
    "\n",
    "for col in ColAttributes:\n",
    "    colDF = colDF.append(col.presentColAttri(), ignore_index=True)\n",
    "    \n",
    "print(colDF.shape)\n",
    "colDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop police force atribut because all entries have same value\n",
    "#drop Junction_control and 2nd_road_class beacuse they have over 20% missing entries\n",
    "\n",
    "data.drop(columns=['Police_Force', 'Junction_Control', '2nd_Road_Class'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data with outliers\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding outliers \n",
    "excludeCol = {'Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude', 'Local_Authority_(Highway)', 'Local_Authority_(District)', 'LSOA_of_Accident_Location', '1st_Road_Number', '2nd_Road_Number', 'Time', 'Date'}\n",
    "numericCol = {'Number_of_Casualties', 'Number_of_Vehicles', 'DateVals', 'TimeVals' }\n",
    "categorCol = (set(data.columns.to_list()) - numericCol) - excludeCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detectioction of numeric Cols: colName, std, mean, lower, upper, numOfOutliers\n",
    "outNumData = pd.DataFrame(columns=['name', 'std', 'mean', 'lower', 'upper', 'numOfOutliers'])\n",
    "outNumIndex = []\n",
    "\n",
    "for i in numericCol:\n",
    "    \n",
    "    std = data[i].std()\n",
    "    mean = data[i].mean()\n",
    "    lower = mean - 3 * std\n",
    "    upper = mean + 3 * std\n",
    "    count = 0\n",
    "    \n",
    "    for row in data[i]:\n",
    "        if ((row < lower) | (row > upper)):\n",
    "            count += 1\n",
    "            \n",
    "    if (count == 0):\n",
    "        continue\n",
    "    \n",
    "    vals = {'name':i, 'std':std, 'mean':mean, 'lower':lower, 'upper':upper, 'numOfOutliers':count}\n",
    "    outNumData = outNumData.append(vals, ignore_index=True)\n",
    "    \n",
    "outNumData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numOfRows = data.shape[0]\n",
    "\n",
    "thrshldCalc = [0, 0]\n",
    "for i in outNumData['numOfOutliers']:\n",
    "    thrshldCalc[0] += i\n",
    "    thrshldCalc[1] += 1\n",
    "    \n",
    "thrshld = thrshldCalc[0] / thrshldCalc[1]\n",
    "\n",
    "avgTPerc = thrshld / numOfRows\n",
    "lwrTPerc = outNumData['numOfOutliers'].min() / numOfRows\n",
    "print(numOfRows, avgTPerc, lwrTPerc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detectioction of categorical Cols: colName, value, rate\n",
    "outCatData = pd.DataFrame(columns=['name', 'value', 'number', 'rate'])\n",
    "\n",
    "percent = lwrTPerc\n",
    "\n",
    "for i in categorCol:\n",
    "    \n",
    "    colValDict = dict(data[i].value_counts())\n",
    "    \n",
    "    for v in colValDict.keys():\n",
    "        \n",
    "        if(v == -1):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if(colValDict[v] / numOfRows < percent):\n",
    "            vals = {'name': i, 'value':v, 'number': colValDict[v], 'rate':(colValDict[v] / numOfRows) * 100}\n",
    "            outCatData = outCatData.append(vals, ignore_index=True)\n",
    "\n",
    "outCatData.sort_values(by=['rate'], inplace=True)\n",
    "outCatData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oulier Categorical descriptive df: colName, numOfValues\n",
    "outDescData = pd.DataFrame(columns=['name', 'flaggedVals', 'totalVals', 'flaggedPerc', 'dominant'])\n",
    "percDict = dict.fromkeys(outCatData['name'].unique().tolist(), 0)\n",
    "\n",
    "for i in outCatData['name'].unique().tolist():\n",
    "    num = 0\n",
    "    \n",
    "    for p in outCatData.loc[outCatData['name'] == i]['rate']:\n",
    "        percDict[i] += p\n",
    "        num += 1\n",
    "        \n",
    "    g = colDF.loc[colDF['Name'] == i]['Unique']\n",
    "    \n",
    "    domi = False\n",
    "    if(g.iloc[0] - num == 1):\n",
    "        domi = True\n",
    "    \n",
    "    vals = {'name': i, 'flaggedVals': num, 'totalVals': g.iloc[0], 'flaggedPerc': percDict[i], 'dominant': domi}\n",
    "    outDescData = outDescData.append(vals, ignore_index=True)\n",
    "\n",
    "outDescData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unFlagCatCol = categorCol - set(outDescData['name'].to_list())\n",
    "unFlagCatCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe with all outliers and removing them from the data dataframe\n",
    "\n",
    "outRecords = pd.DataFrame(columns = data.columns.to_list())\n",
    "\n",
    "datDict = dict(data.dtypes)\n",
    "\n",
    "for key, val in datDict.items():\n",
    "    if val == 'int64' or val == 'float64':\n",
    "        outRecords[key] = pd.to_numeric(outRecords[key])\n",
    "    if key == 'Date':\n",
    "        outRecords['Date'] = pd.to_datetime(outRecords['Date'], format='%d/%m/%Y')\n",
    "    if key == 'Time':\n",
    "        outRecords['Time'] = pd.to_datetime(outRecords['Time'], format='%H:%M')\n",
    "        \n",
    "#removing numeric outliers\n",
    "for i in outNumData['name'].unique():\n",
    "    upper = outNumData.loc[outNumData['name'] == i]['upper'].tolist()[0]\n",
    "    lower = outNumData.loc[outNumData['name'] == i]['lower'].tolist()[0]\n",
    "    outs = data.loc[(data[i] > upper) | (data[i] < lower)]\n",
    "    data.drop(index = data.index[(data[i] > upper) | (data[i] < lower)].tolist(), inplace = True)\n",
    "    outRecords = pd.concat([outRecords, outs])\n",
    "    \n",
    "    \n",
    "print(data.shape)\n",
    "print(outRecords.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing categorical outliers\n",
    "for i in outCatData['name'].unique():\n",
    "    vals = outCatData.loc[outCatData['name'] == i]['value'].tolist()\n",
    "    for v in vals:\n",
    "        outs = data.loc[data[i] == v]\n",
    "        data.drop(index = data.index[data[i] == v].tolist(), inplace = True)\n",
    "        outRecords = pd.concat([outRecords, outs])\n",
    "        \n",
    "print(data.shape)\n",
    "print(outRecords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColAttributes2 = []\n",
    "dataDict = dict(data.dtypes)\n",
    "\n",
    "for key, val in dataDict.items():\n",
    "    currCol = ColumnAttri(key, val)\n",
    "    currCol.processCol(data)\n",
    "    ColAttributes2.append(currCol)\n",
    "\n",
    "colDF2 = pd.DataFrame(columns=['Name','Type', 'Empty', 'Full', 'Ratio', 'Min', 'Max', 'Unique'])\n",
    "\n",
    "for col in ColAttributes2:\n",
    "    colDF2 = colDF2.append(col.presentColAttri(), ignore_index=True)\n",
    "    \n",
    "print(colDF2.shape)\n",
    "colDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping all columns that only have 1 unique value\n",
    "#the value in all the columsn was 0 signifying none, view document for extra info\n",
    "print(data['Carriageway_Hazards'].unique())\n",
    "print(data['Special_Conditions_at_Site'].unique())\n",
    "print(data['Pedestrian_Crossing-Human_Control'].unique())\n",
    "\n",
    "categorCol.remove('Carriageway_Hazards')\n",
    "categorCol.remove('Pedestrian_Crossing-Human_Control')\n",
    "categorCol.remove('Special_Conditions_at_Site')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Carriageway_Hazards', 'Special_Conditions_at_Site', 'Pedestrian_Crossing-Human_Control'], inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting outlier free and clean data\n",
    "\n",
    "data.to_csv(path_or_buf='/Users/othmanetazi/Desktop/DMA_ousework/data1.csv', index = False)\n",
    "print(numericCol)\n",
    "print(categorCol)\n",
    "print(excludeCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlatio for categorical attrbutes by factorizing them then using person\n",
    "factorDf = pd.DataFrame()\n",
    "\n",
    "for i in categorCol:\n",
    "    vals, indexes = pd.factorize(data[i])\n",
    "    factorDf[i] = vals\n",
    "    \n",
    "corrfCat = factorDf.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get correlatio for all attrbutes by factorizing categorical attributes then using person\n",
    "\n",
    "for i in numericCol:\n",
    "    factorDf[i] = data[i]\n",
    "    \n",
    "corrfAll = factorDf.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#correlation analysis on the Catgorical columns\n",
    "corrCat = data.loc[: , categorCol].corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis on the Numeric columns\n",
    "corrNum = data.loc[: , numericCol].corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation analysis on the All columns\n",
    "numAndCatCol = set.union(numericCol, categorCol)\n",
    "corrAll = data.loc[: , numAndCatCol].corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrDfList = [corrNum, corrCat, corrfCat, corrAll, corrfAll]\n",
    "corrDescList = []\n",
    "\n",
    "def corrDesc(corrDf):\n",
    "    corrDescDf = pd.DataFrame(columns=['name', 'highName', 'highVal', 'lowName', 'lowVal'])\n",
    "    corrIndx = corrDf.index.tolist()\n",
    "\n",
    "    for i in corrIndx:\n",
    "        row = dict(corrDf.loc[i, :])\n",
    "\n",
    "        holder = list(row.keys())[0]\n",
    "        if (holder == i):\n",
    "            holder = list(row.keys())[1]\n",
    "\n",
    "        high = [holder, row[holder]]\n",
    "        low = [holder,row[holder]]\n",
    "\n",
    "        for k, v in row.items():\n",
    "            if (i == k):\n",
    "                continue\n",
    "\n",
    "            if (v > high[1]):\n",
    "                high[0] = k\n",
    "                high[1] = v\n",
    "\n",
    "            if (v < low[1]):\n",
    "                low[0] = k\n",
    "                low[1] = v\n",
    "\n",
    "        vals = {'name': i, 'highName': high[0], 'highVal': high[1], 'lowName': low[0], 'lowVal': low[1]}\n",
    "        corrDescDf = corrDescDf.append(vals, ignore_index=True)\n",
    "    \n",
    "    return corrDescDf\n",
    "\n",
    "\n",
    "for i in corrDfList:\n",
    "    corrDescList.append(corrDesc(i))\n",
    "    \n",
    "for i in corrDescList:\n",
    "    i.sort_values(by=['highVal'], inplace=True)\n",
    "    print(i.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Numeric')\n",
    "corrDescList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical non-Factorized')\n",
    "corrDescList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Categorical Factorized')\n",
    "corrDescList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All non-Factorized')\n",
    "corrDescList[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Factorized')\n",
    "corrDescList[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling Ideas:\n",
    "    #descriptive:\n",
    "    #predictive: time to severity, weather condition to surface conditions\n",
    "    \n",
    "    #see if we can observe day light savings based of light condition / datevals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valColor = {1:'blue', 2:'green', 3:'red'}\n",
    "\n",
    "for e in eList:\n",
    "    e.plot(kind='scatter', x='Longitude', y='Latitude', c=e['Accident_Severity'].map(valColor), figsize=(7, 7), alpha = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DateVals'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TimeVals'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in eList:\n",
    "    e['TimeVals'].hist(alpha= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percDict = dict.fromkeys(outCatData['name'].unique(), 0)\n",
    "percDict\n",
    "\n",
    "test = outCatData['name'].unique()\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhd = outCatData.loc[outCatData['name'] == 'Junction_Detail']['value'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jhd:\n",
    "    test = data.loc[data['Junction_Detail'] == i]\n",
    "    print(test.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'].value_counts()[:1].index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
